\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
%\usepackage{breakurl}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\makeatother

\begin{document}

%% still can't get paths to work ...
\SweaveOpts{path=fig/hw7-,fig.align=center,fig.show=hold,dev=png,fig.width=6,fig.height=4}

<<setup,echo=FALSE,results=hide,message=FALSE>>=
options(replace.assign=TRUE,width=90)
knit_hooks$set(par=function(before, options, envir){if (before) par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3,las=1)})
require(bbmle)
require(rethinking)
require(ggplot2)
require(emdbook)

@

\begin{center}
  {\bf \Large Homework 8, Statistical Rethinking}\\
\vspace{12pt}
   {\large Jaime Ashander}
\end{center}

\subsection*{Morality and predictors}

I'm fitting data from a survey regarding various trolley problems. 
As discussed in class the data is coded into scenarios for ``action'' ``intention'' and ``contact''.

<<load, message=FALSE>>=

data(trolley)
d <- trolley
@ 

\subsubsection*{(a)}


Building on a base model where intention interacts (separately) with action and contact, II model an interaction between gender and contact, and also look at a model without the interaction, but with gender. 

<<polr-gender,message=TRUE,cache=TRUE,warning=FALSE>>=

m1 <- polr( as.ordered(response) ~ action * intention + contact * intention, data=d , Hess=TRUE )
m2 <- polr( as.ordered(response) ~ action * intention + contact * intention + male * contact , data=d , Hess=TRUE )
m3 <- polr( as.ordered(response) ~ action * intention + contact * intention + male  , data=d , Hess=TRUE )

compare(m1,m2,m3,nobs=nrow(d))
coeftab(m2,m3)[1:7,]
precis(m2)[1:7,]
@ 


Either by itself, or interacting with contact, gender improves the model. 
The favored models indicate an effect of gender, where a positive coefficient on male indicates greater likelihood of rating actions as permissible (i.e. higher numbers on the likert scale).
The negative interaction indicates that males may be {\em less} likely to rate contact scenarios highly (after correcting for the postive male effect overall).

Model averaging is equivocal on the question of an interaction. 
Both AICc and BIC put some weight on each of the models with gender (with and without an interaction). 
BIC favors the interaction-less model, while AIC the other. 
As a conservative test, I'll use model averaging based on AICc (which seems to favor an interaction between contact and gender) to  check for support for the interaction in plotted results. 


<<trolley-plots,message=FALSE,cache=TRUE>>=
post <- sample.naive.posterior(list(m2,m3), n=2e4, method='AICc', nobs=nrow(d))
prob.indices <- grep("\\|", names(post2))

op <- par(mfrow=c(2,2))

for(kI in 0:1){
  for(kA in 0:1){
    kC <- 0:1 
    plot(1,1, type='n', xlab='contact', ylab='probability', xlim=c(0,1), ylim=c(0,1), xaxp=c(0,1,1), yaxp=c(0,1,2))
    col.vec=c('grey','black')
    ci.vec=c('black','white')

    title(paste('action',kA,'male 0:1','intent',kI))

    for(kM in 0:1){
      for(s in 1:200){
        p <- post[s,]
        ak <- as.numeric(p[prob.indices])
        phi <- with(p, kA*action + kI*intention + kC*contact + kA*kI*`action:intention` + kC*kI*`intention:contact`+kM*kC*`contact:male` + kM*male)
        pk <- pordlogit(1:6, a=ak, phi=phi)
        for(i in 1:6)
          lines(kC, pk[,i], col=col.alpha(col.vec[kM+1], 0.01))
      }
      pmle <- as.list(coef(m2))
      if(class(m2)=='polr')
        ak <- m2$zeta
      phi <-  with(pmle, kA*action + kI*intention + kC*contact + kA*kI*`action:intention` + kC*kI*`intention:contact`+kM*kC*`contact:male` + kM*male)
      pk.mle <- pordlogit(1:6, a=ak, phi=phi)
      for(i in 1:6) lines(0:1, pk.mle[,i], col=ci.vec[kM+1])
    }
  }
}
par(op)

@


Above depicts (model-averaged) effect of contact for female (light gray w/ black center lines) and male (dark gray w/ white centerlines). 
In these figures,  a gender$\times$contact interaction will appear as a difference in slopes between the male (white) and female(black) responses. 
{\em Without contact}, females tend to  favor lower values than males across all scenarios (white line below black more or less).
Males consistently respond more {\em negatively} to contact scearios (the slopes of white lines are steeper). 
This effect appears stronger at lower and higher ends of the scale, and at the lower end of the scale are strong enough to mean males are less permissive! 


<<interact-coef,message=TRUE,cache=TRUE,warning=FALSE>>=
o
p <- par(mfrow=c(2,2))
dens(post$male + post$`contact:male` + post$contact, main='Male + Contact')
dens( post$contact, main='Female + Contact')
dens(post$male + post$`contact:male` + post$contact + post$`intention:contact` + post$intention, main='M + C + Intention')
dens(post$contact+ post$`intention:contact` + post$intention, main='F + C + Intention')
par(op)

@ 

Model-averaged value for overall effect of being male versus female in a contact scenario without (top row) and with (bottom row) intention. 
The averaged coefficients depicted here still seem to indicate uni-directional effects, in contrast to the crossing responses shown in the earlier plots. 
I can't quite reconcile these: either I've made a mistake plotting, or the interpretation of log-odds is confusing me....


\subsubsection*{(b)}


Here, I consider the effect of age as a linear, quadratic, or cubic polynomial. 
To aid fitting, I constructed standardized predictors based on the powers of age: 

<<polr-age,message=TRUE,cache=TRUE,warning=FALSE>>=
Standardize <- function(x) { 
  (x - mean(x))/sd(x)
}
d$age1 <- Standardize(d$age)
d$age2 <- Standardize(d$age^2) 
d$age3 <- Standardize(d$age^3) 

m4 <- polr( as.ordered(response) ~ action * intention + contact * intention + Standardize(age), data=d , Hess=TRUE )
m5 <- polr( as.ordered(response) ~ action * intention + contact * intention + Standardize(age) + Standardize(age^2), data=d , Hess=TRUE )
m6 <- polr( as.ordered(response) ~ action * intention + contact * intention + Standardize(age) + Standardize(age^2) + Standardize(age^3), data=d , Hess=TRUE )

compare(m4,m5,m6,nobs=nrow(d))

coeftab(m4,m5,m6)[1:6,]

#precis(m6)

@ 

Model selection {\em strongly} supported a non-linear effect of age, a cubic polynomial.
The parameter values are very difficult to interpret on their own so I've left them out. 

<<mod-avg-age,message=TRUE,cache=TRUE>>=
post2 <- sample.naive.posterior(list(m5,m6),method='AICc',nobs=nrow(d), n=2e4)
prob.indices <- grep("\\|", names(post2))

avg.coef <- colMeans(post2)


ages <- min(d$age):max(d$age)
for(kC in 0:1){
  op <- par(mfrow=c(2,2))
  for(kA in 0:1){
    for(kI in 0:1)
      {
        plot(1,1, xlab='age', ylab='probability', xlim=range(d$age), ylim=c(0,1), yaxp=c(0,1,2)) 

        title(paste('act',kA,'inten',kI,'cont',kC))

        for(s in 1:200){
          p <- post2[s,]
          ak <- as.numeric(p[prob.indices])
          phi <- with(p, kA*action + kI*intention + kC*contact + kA*kI*`action:intention` + kC*kI*`intention:contact` + Standardize(ages)*`Standardize(age)` + Standardize(ages^2)*`Standardize(age^2)` + Standardize(ages^3)*`Standardize(age^3)`)
          pk <- pordlogit(1:6, a=ak, phi=phi)
          for(i in 1:6)
            lines(ages, pk[,i], col=col.alpha("grey", 0.01))
        }
        pmle <- as.list(avg.coef)
        ak <- avg.coef[prob.indices]
        phi <- with(pmle, kA*action + kI*intention + kC*contact + kA*kI*`action:intention` + kC*kI*`intention:contact` + Standardize(ages)*`Standardize(age)` + Standardize(ages^2)*`Standardize(age^2)` + Standardize(ages^3)*`Standardize(age^3)`)    
        pk.mle <- pordlogit(1:6, a=ak, phi=phi)
        for(i in 1:6) lines(ages, pk.mle[,i], col="black")
      }
  }
  par(op)
}

@ 

The above figures depict the effect of age on response across contact (first four-panel) and non-contact (second four-panel) scenarios. 
Across all scenarios, there was a consistent effect of age in {\em decreasing} permissiveness in the middle of the age range: both young and old folks are more morally permissive than middle aged folks. 

\subsection*{Basketball}

Now fitting binomial and beta-binomial models to predict basketball shooting percentage:

<<load-b,message=FALSE>>=
d <- read.csv('fieldgoals0708.csv')
d <- d[order(d$FGM),]               
d$ID <- seq_along(d$player)
head(d, n=1)

@ 

First I wrote a beta-binomial density 

<<beta-binom,message=FALSE>>=
dbetabinom2 <- function(x, pbar,  theta, size, log=FALSE){
  #using PMF from http://en.wikipedia.org/wiki/Beta-binomial_distribution with 
  n <- size
  k <- x
  a <- pbar*theta 
  b <- (1-pbar)*theta
  lp <- lchoose(n,k)+lbeta(k+a, n-k +b) - lbeta(a,b) #rewritten to log after looking at Bolker's emdbook::dbetabinom
  if(log)
    return(lp)
  else return(exp(lp))
  }

@ 

\subsubsection*{(a)}

I fit beta and beta-binomial models without any predictor. 

<<binom,message=FALSE,cache=TRUE>>=

m2b <- mle2(FGM ~ dbinom(prob=logistic(a), size=FGA), data=d, start=list(a=0))
m2bb <- mle2(FGM ~ dbetabinom2(pbar=logistic(a), theta=theta, size=FGA), data=d, start=list(a=0, theta=2))
compare(m2b, m2bb, nobs=sum(d$FGA))
precis(m2bb)
@ 


<<post-bs,message=FALSE,cache=TRUE,warning=FALSE>>=
post.b1 <-sample.naive.posterior(m2b)
post.bb1 <- sample.naive.posterior(m2bb)
id.seq <- d$ID #seq(min(d$FGA), max(d$FGA), by=4)

mu <- sapply(id.seq, function(i) mean(rbinom(n=1e4, prob=logistic(post.b1$a), size=d$FGA[i])))
mu.ci <- sapply(id.seq, function(i) PCI(rbinom(n=1e4, prob=logistic(post.b1$a), size=d$FGA[i])))

Plot0 <- function(d, mu, mu.ci){
  plot(FGM/FGA~ID, data=d, xlab='Player ID',col=col.alpha('gray', 0.5), pch=19, ylim=c(0,1))
  lines(id.seq, mu.ci[1,]/d$FGA, lty=2)
  lines(id.seq, mu.ci[2,]/d$FGA, lty=2)
  lines(mu/FGA~id.seq, data=d)
}
op <- par(mfrow=c(2,2))
Plot0(d, mu, mu.ci)
dens(logistic(post.b1$a), xlim=c(.3,.6))
title('binomial probability')

prob <- rbeta2(n=1e4, prob=logistic(post.bb1$a), theta=post.bb1$theta)
mu <- sapply(id.seq, function(i) mean(rbinom(n=1e4, prob=prob, size=d$FGA[i])))
mu.ci <- sapply(id.seq, function(i) PCI(rbinom(n=1e4, prob=prob, size=d$FGA[i])))               

Plot0(d, mu, mu.ci)

prob.dens <- rbeta2(nrow(d)*100, prob=logistic(post.bb1$a), theta=post.bb1$theta)
dens(prob.dens, xlim=c(.3,.6))
title('beta-binomial probability')
par(op)
@ 

The above plots show field goals made over attempted plotted against player ID (assigned in order of shooting percentage), as well as posteior densities of the probability coefficient. 
The first row is the binomial model and the second is the beta-binomial.

The beta binomial distribution does a much better job capturing the spread in the data. 
This is because the mixture does not have the same constrained relationship between mean and variance as the binomial.

\subsubsection{(b)}

Still working with scaled attempts and successes, we fit the model 

(with FGA as predictor)

<<binom-w-pred,message=FALSE,cache=TRUE,warning=FALSE>>=
d <- read.csv('fieldgoals0708.csv')
d <- d[order(d$FGM),]               
d$ID <- seq_along(d$player)

#max.attempts <- max(d$FGA) 
m3b <- mle2(FGM ~ dbinom(prob=logistic(a+b*FGA/max(FGA)), size=FGA), data=d, start=list(a=0, b=0))
m3bb <- mle2(FGM ~ dbetabinom2(pbar=logistic(a+b*FGA/max(FGA)), theta=theta, size=FGA), data=d, start=list(a=0, b=0, theta=2))
coeftab(m3b,m3bb)
compare(m3b, m3bb, nobs=sum(d$FGA))
@

The coefficient on attempts ({\tt b}) indicates that those shooting more often have a {\em lower} chance of hitting baskets. 
Model averaging is strongly in favor of a beta-binomial formulation. 


<<post-bs-w-pred,message=FALSE,cache=TRUE>>=
post.b2 <-sample.naive.posterior(m3b)
post.bb2 <- sample.naive.posterior(m3bb)
id.seq <- d$ID #seq(min(d$FGA), max(d$FGA), by=4)

post.b2$b <- post.b2$b/max(d$FGA) ## rescale posterior coefficient as in fitted equation
post.bb2$b <- post.bb2$b/max(d$FGA)

mu <- sapply(id.seq, function(i) mean(rbinom(n=1e4, prob=logistic(post.b2$a+post.b2$b*d$FGA[i]), size=d$FGA[i])))
mu.ci <- sapply(id.seq, function(i) PCI(rbinom(n=1e4, prob=logistic(post.b2$a+post.b2$b*d$FGA[i]), size=d$FGA[i])))

Plot1 <- function(POST, mu, mu.ci, D=d, betabin=FALSE){
  plot(FGM/FGA~FGA, data=D, pch='', ylim=c(0,1))
  for(i in 1:length(id.seq)) with(D, lines(rep(FGA[i],2), c(mu.ci[,i]/FGA[i]),col='lightgrey', lwd=1.5))
  for(i in 1:length(id.seq)) with(D, points(rep(FGA[i],2), c(mu.ci[,i]/FGA[i]),pch='-', cex=.75))
  points(FGM/FGA~FGA, data=D,col=col.alpha('darkgray', 0.8), pch=19)
  points(mu/FGA~FGA, data=D, pch=19, cex=0.5)

  if(betabin){
    prob.dens3 <- rbeta2(nrow(d)*100, prob=logistic(POST$a+ POST$b*d$FGA), theta=POST$theta)
    dens(prob.dens3,xlim=c(.3,.6))
    title('beta binomial probability')
    return(prob.dens3)
    }
  dens(with(POST,  logistic(a + b*with(D, FGA))),xlim=c(.3,.6))
  title('binomial probability')
  return(NULL)
}
op <- par(mfrow=c(2,2))
tmp <- Plot1(post.b2, mu, mu.ci, d)

mu <- sapply(id.seq, function(i) mean(rbinom(n=1e4, prob=rbeta2(n=1e4, prob=logistic(post.bb2$a+post.bb2$b*d$FGA[i]), theta=post.bb2$theta), size=d$FGA[i])))
mu.ci <- sapply(id.seq, function(i) PCI(rbinom(n=1e4, prob=rbeta2(n=1e4, prob=logistic(post.bb2$a+post.bb2$b*d$FGA[i]), theta=post.bb2$theta), size=d$FGA[i])))               

tmp <- Plot1(post.bb2, mu, mu.ci, d, TRUE)
  par(op)

@ 

The plots bear out the coefficient: taking more attempts have {\em a lower chance} of making the baskets.
However the effect is failry weak given the uncertainty (gray bars). 
Perhaps those who shoot more often shoot from further away? The field goals category does mix three and two pointers. 


\subsubsection{(c)}

Now to look at three pointers alone. 
Perhaps here I'll see a stronger signal.

First I construct colums for  three-pointer attempts ({\tt TA}) and goals ({\tt TM}): 

<<binom-3pt,message=FALSE,cache=TRUE,warning=FALSE>>=
d <- read.csv('fieldgoals0708.csv')
d <- d[order(d$FGM),]               
d$ID <- seq_along(d$player)
d$TM <- d$FGM-d$X2PM
d$TA <- d$FGA-d$X2PA

m4b <- mle2(TM ~ dbinom(prob=logistic(a+bT*TA), size=TA), data=d, start=list(a=0, bT=0))
m4bb <- mle2(TM ~ dbetabinom2(pbar=logistic(a+bT*TA ), theta=exp(tau), size=TA), data=d, start=list(a=0, bT=0, tau=log(2)))
m4bb2 <- mle2(TM ~ dbetabinom2(pbar=logistic(a+bT*TA + bA*FGA), theta=exp(tau), size=TA), data=d, start=list(a=0, bT=0, bA=0, tau=log(2)))

compare(m4b, m4bb, m4bb2, nobs=sum(d$TA))
coeftab(m4b,m4bb)
@

With the above model formulation, I had no issues fitting, likely because the exponential parameterization {\tt theta = exp(tau)} could easily work with large values of {\tt theta}. 

Here, attempting more threes appears to help one's chances of making a three point shot (coefficient {\tt bT} $>0$). 
Interestingly, although BIC and AICc agree that the beta-binomial formulation is superior, there is some weight remaining on the binomial model.

<<post-bs-threes,message=FALSE,cache=TRUE,warning=FALSE>>=
post.b3 <-sample.naive.posterior(m4b)
post.bb3 <- sample.naive.posterior(m4bb)
id.seq <- d$ID #seq(min(d$TA), max(d$TA), by=4)

mu <- sapply(id.seq, function(i) mean(rbinom(n=1e4, prob=logistic(post.b3$a+post.b3$bT*d$TA[i]), size=d$TA[i])))
mu.ci <- sapply(id.seq, function(i) PCI(rbinom(n=1e4, prob=logistic(post.b3$a+post.b3$bT*d$TA[i]), size=d$TA[i])))


Plot2 <- function(POST, mu, mu.ci, D=d, betabin=FALSE){

  plot(TM/TA~log(TA), data=D, pch='', ylim=c(0,1))
  for(i in 1:length(id.seq)) with(D, lines(rep(log(TA[i]),2), c(mu.ci[,i]/TA[i]),col='lightgrey', lwd=1.5))
  for(i in 1:length(id.seq)) with(D, points(rep(log(TA[i]),2), c(mu.ci[,i]/TA[i]),pch='-', cex=.75))
  points(TM/TA~log(TA), data=D,col=col.alpha('darkgray', 0.8), pch=19)
  points(mu/TA~log(TA), data=D, pch=19, cex=0.5)
  
  if(betabin){
    prob.dens3 <- rbeta2(nrow(d)*100, prob=logistic(POST$a+POST$bT*d$TA), theta=exp(POST$tau))
    dens(prob.dens3,xlim=c(.2,.5))
    title('beta binomial probability')
    return(prob.dens3)
    }
  dens(with(POST,  logistic(a + bT*with(D, TA))),xlim=c(.2,.5))
  title('binomial probability')
  return(NULL)
}
  op <- par(mfrow=c(2,2))
tmp <- Plot2(post.b3, mu, mu.ci, d)

mu <- sapply(id.seq, function(i) mean(rbinom(n=1e4, prob=rbeta2(n=1e4, prob=logistic(post.bb3$a+post.bb3$bT*d$TA[i]), theta=exp(post.bb3$tau)), size=d$TA[i])))
mu.ci <- sapply(id.seq, function(i) PCI(rbinom(n=1e4, prob=rbeta2(n=1e4, prob=logistic(post.bb3$a+post.bb3$bT*d$TA[i]), theta=exp(post.bb3$tau)), size=d$TA[i])))               

tmp <- Plot2(post.bb3, mu, mu.ci, d, TRUE)
par(op)

@ 

In contrast to the situation with all field goals, three pointers (i) are postively correlated with three-point attempts, and (ii) fairly well-explained by a binomial-only model with log odds predicted by attempts. 
It seems the heterogeneity in attempts is high enough to capture the heterogeneity in outcomes (see coefficient density plots above right column). 

\newpage
\subsection*{Colophon}

<<runit,eval=FALSE>>=
require(knitr) ### the package
knit(paste(getwd(),'hw8ashander.Rnw',sep='/')) ## to run1

##x to use all cores
require(snowfall)
sfInit(parallel=TRUE,cpus=4)
sfLibrary(rethinking)
sfExportAll()
sfStop()
@ 

<<other-ideas,eval=FALSE>>=
## make 'error bars'
#

@ 

\end{document}
