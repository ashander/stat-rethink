\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
%\usepackage{breakurl}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\makeatother

\begin{document}

%% still can't get paths to work ...
%\SweaveOpts{path=fig/hw7-,fig.align=center,fig.show=hold,dev=png,fig.width=6,fig.height=4}

<<setup,echo=FALSE,results=hide,message=FALSE>>=
options(replace.assign=TRUE,width=90)
knit_hooks$set(par=function(before, options, envir){if (before) par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3,las=1)})
require(bbmle)
require(rethinking)
require(ggplot2)
@

\begin{center}
  {\bf \Large Homework 7, Statistical Rethinking}\\
\vspace{12pt}
   {\large Jaime Ashander}
\end{center}

\subsection*{Pirating eagles}

<<load,message=FALSE>>=
data(eagles)
d <- eagles
names(d)

@ 

I seek to predict successful pirating attempts {\tt y} of all attempts {\tt n} based on the size {\tt P} and age {\tt A} of the pirate and the size {\tt V} of the victim.

\subsubsection*{(A)}

To do this, I fit the binomial model:
\begin{align*}
&y_i \sim {\rm Binomial} ( p_i , n_i)\\
&\log \frac{p_i}{1-p_i} = \alpha + \beta_P P_i + \beta_V V_i + \beta_A A_i
\end{align*}

To fit the model, I code dummy variables $P$: {\tt pirateL}, $V$: {\tt victimL}, $A$: {\tt pirateA}.
<<var-code,message=FALSE>>=
d$pirateL <- ifelse(d$P=='L',1,0)
d$pirateA <- ifelse(d$A=='A',1,0)
d$victimL <- ifelse(d$V=='L',1,0)
d[,6:8] <- apply(d[,6:8], 2, function(x) x-mean(x))
@ 
I also recenter the predictors to aid interpretation of interaction coefficients. 

To fit the model, I use the logit link function.
In practice, this means using the logistic (inverse link) tranform on the linear model for the log odds (the RHS of the second equation above):

<<pirate-model,message=FALSE>>=
m1a <- mle2(y ~ dbinom(prob=logistic(a + bP*pirateL+bV*victimL + bA*pirateA), size=n), data=d, start=list(a=mean(d$y), bP=0, bV=0, bA=0))
p.m1 <- precis(m1a)
point.est <- as.data.frame(t(p.m1$Estimate))
names(point.est) <- row.names(p.m1)
p.m1

@ 

The baseline probability of success (i.e. given default vales for dummy variables) corresponds to a small, young pirate versus a small victim.
In this case, the probability of success in an attack is a bit over half (0.65 = logistic($\alpha$)).
A larger or older eagle has a greater chance of success, but being larger is more helpful than being older. 
An attack on a larger victim is less likely to succeed. 
The effect of largeness in either the victim or pirate on log-odds of success is about equal, or slightly in favor of the victim (but opposite). 

<<probs,echo=FALSE>>=
cat('small, young v small',  logistic(with(point.est, a)),'\n')
#cat('small, old v small', logistic(with(point.est, bA+a)), '\n')
cat('large, young v small', logistic(with(point.est, a+bP)), '\n')
cat('large, young v large', logistic(with(point.est, a+bP+bV)), '\n')
cat('large, old v small', logistic(with(point.est, a+bP+bA)), '\n')
#cat('large, old v large',logistic(with(point.est, a+bP+bA+bV)), '\n')
#cat('small, old v large',logistic(with(point.est, a+bA+bV)),'\n')
#cat('small, young v large', logistic(with(point.est, a+bV)), '\n')
@ 

\subsubsection*{(B)}

<<pirate-plot-b1,message=TRUE,cache=TRUE>>=
post <- sample.naive.posterior( m1a)

y.pred <- sapply( 1:nrow(d) , function(i) mean( rbinom( n=10000 , prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] ) , size=d$n[i] ) ) )

y.pred.ci <- sapply( 1:nrow(d) , function(i) PCI( rbinom( n=10000 , prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] ) , size=d$n[i] ) ) )

op <- par(mfrow=c(2,1))
plot( (1:8)+0.2 , d$y , col="slateblue" , ylab="successful attempts" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,31), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]),col='grey')
points( 1:8 , y.pred ,pch=19,cex=0.5,col='black')

plot( (1:8)+0.2 , d$y/d$n , col="slateblue" , ylab="proportion successful" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,1), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]/d$n[i]),col='grey')
points( 1:8 , y.pred/d$n ,pch=19,cex=0.5,col='black')

par(op)

@ 

Across encounter types, the plot of successful counts (top figure), does a better job heterogeneity in relative frequency of successful attempts, while the plot of proportions (bottom figure) shows differences in probability.
In the count plot, the confidence intervals and point estimates are easier to interpret relative to the data as they are in the same units.
On the other hand, in the plot of proportions of successs the estimates are interpretable in terms of success probability. 
Further, in the lower plot, the intervals provide a fuller graphical sense of uncertainty in outcome.

Taken together, the two plots give a sense of the total number of various types of encounters in the data set. 
Neither plot shows this directly. 

\subsubsection*{(C)}

I'd like to improve the model, so I fit a model with an interaction between pirate age and pirate size
\begin{align*}
&y_i \sim {\rm Binomial} ( p_i , n_i)\\
&\log \frac{p_i}{1-p_i} = \alpha + \beta_P P_i + \beta_V V_i + \beta_A A_i + \beta_{PA} P_i \cdot A_i
\end{align*}

<<better-model,message=FALSE,cache=TRUE>>=
m1c <- mle2(y ~ dbinom(prob=logistic(a + bP*pirateL + bV*victimL + bA*pirateA + bPA*pirateL*pirateA), size=n), data=d, start=list(a=mean(d$y), bP=0, bV=0, bA=0, bPA=0))
p.m1c <- precis(m1c)

compare(m1a,m1c, nobs=sum(d$n))
@ 

Both BIC and AICc agree that the interaction improves the model. 
According to both criteria, an averaged model would include about 10 \% of the non-interaction model. 

<<better-model-fig,message=FALSE,cache=TRUE>>=
post2 <- sample.naive.posterior( list(m1a,m1c),method='AICc', nobs=sum(d$n),n=3e4)

y.pred <- sapply( 1:nrow(d) , function(i) mean( rbinom( n=10000, prob=logistic( post2$a + post2$bP*d$pirateL[i] + post2$bV*d$victimL[i] + post2$bA*d$pirateA[i] + post2$bPA*d$pirateL[i]*d$pirateA[i] ) , size=d$n[i] ) ) )

y.pred.ci <- sapply( 1:nrow(d) , function(i) PCI( rbinom( n=10000, prob=logistic( post2$a + post2$bP*d$pirateL[i] + post2$bV*d$victimL[i] + post2$bA*d$pirateA[i] + post2$bPA*d$pirateL[i]*d$pirateA[i] ) , size=d$n[i] ) ) )

op <- par(mfrow=c(2,1))
plot( (1:8)+0.2 , d$y , col="slateblue" , ylab="successful attempts" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,31), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]),col='grey')
points( 1:8 , y.pred ,pch=19,cex=0.5,col='black')

plot( (1:8)+0.2 , d$y/d$n , col="slateblue" , ylab="proportion successful" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,1), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]/d$n[i]),col='grey')
points( 1:8 , y.pred/d$n ,pch=19,cex=0.5,col='black')

par(op)
p.m1  # precis of m1a
p.m1c # precis of m1c
@ 

As shown in above figures, averaged model (using AICc) does a much better job at prediction.
Model averaging provides support for an interaction between pirate age and size. 

As indicated by the table of coefficients, the effect of the interaction is negative. 
This means that the effects of largeness and adultness are non-additive. 
The improved model estimates a greater effect of size on outcome, and these estimates for either pirate or victim are relatively equal but opposite. 
A small adult pirate has a better chance than a small immature pirate, but (due to the interaction), this advantage of adulthood disappears at large size. A large adult pirate actually does worse than a large immature pirate.


\subsection*{Herptiles}

I'm looking at data for salamander counts per plot from CA. 

<<load-herp,message=FALSE>>=
data(salamanders)
d <- salamanders
head(d,n=1)
d$pc <- d$PCTCOVER - mean(d$PCTCOVER)
d$fs <- d$FORESTAGE - mean(d$FORESTAGE)

@ 

The data set includes counts of salamanders in each plot (SALAMAN), as well as percent (PCTCOVER) and age (FORESTAGE) of ground cover.
I recenter the predictors PCTCOVER to {\tt pc} and FORESTAGE to {\tt fc} in case I want to look at interaction coefficients. 


\subsubsection*{(A)}

I model the count variable SALAMAN as a Poisson variable:
\begin{align*}
&S_i \sim {\rm Poisson} ( \lambda_i)\\
&\log \lambda_i = \alpha + \beta_P *P_i
\end{align*}
where $S_i$ is SALAMAN and $P_i$ is PCTCOVER

<<sal-model,message=FALSE>>=
m2a <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*pc)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0))
precis(m2a)
@ 


<<sal-fig,message=FALSE,cache=TRUE>>=
post <- sample.naive.posterior(m2a)
pct.seq <- seq(min(d$pc),max(d$pc), length.out=100)

y.pred <- sapply(pct.seq , function(z) mean(exp(post$a + post$b.P*z)))

y.pred.ci <- sapply( pct.seq , function(z) PCI(exp(post$a + post$b.P*z)))

y.pred.pi <- sapply( pct.seq , function(z) PCI( rpois( n=3e4, lambda=exp(post$a + post$b.P*z)))) 

plot(SALAMAN~pc, data=d,col=col.alpha('gray', .9), pch=19, xlab='percent cover', xaxt='n')
axis(1, at=pct.seq[c(1, 20, 40, 60, 80)], labels=c(0,2,4,6,8)*10)
lines(pct.seq, y.pred)
lines(pct.seq, y.pred.ci[1,], lty=2)
lines(pct.seq, y.pred.ci[2,], lty=2)
lines(pct.seq, y.pred.pi[1,], lty=3)
lines(pct.seq, y.pred.pi[2,], lty=3)

pairs(d[,c(2:4)])
@ 

The model does a good job at low percent ground cover, with all observation falling within the 95\% PI. 
At very high coverages, however, there are some high counts that are not captured by the model.

Looking at the pairs plot, I can see perhaps why a model based on percent cover alone does a bad job at high counts. 
At high percent cover, there are counts ranging from 0 to 12 (the maximum), thus there is little information in percent cover to predict  at these counts. 



\subsubsection*{(B)}

I'll try to improve the model using age of tree cover (FORESTAGE).
There are a wide range of forestage values at high percent-cover values (in the pairs plot). 
If forestage were a strong predictor of salamander count, a model with both variables could work well. 

On the other hand, also from the pairs plot, the relationship between forestage and salamander does not seem to strong.
I'll see if model selection and averaging bears out our suspicion that forestage can't help much. . . 

<<sal-model,message=FALSE>>=
m2b <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*pc + b.F*fs)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0, b.F=0))
m2c <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*pc + b.F*fs + b.PF*pc*fs)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0, b.F=0, b.PF=0))
m2d <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.F*fs)), data=d, start=list(a=log(mean(d$SALAMAN)), b.F=0))
compare(m2a,m2b,m2c,m2d, nobs=nrow(d))

@ 

There is support for a model that includes both percent cover and forestage, but with more weight on percent cover alone. 
(BIC and AICc agree pretty well here, so it shouldn't matter which I use.)
Averaged predictions (not shown) display no difference from the predictions using percent cover alone. 
This, in part, because forestage is such a poor predictor. 


<<2b-avg, message=FALSE,cache=TRUE,eval=FALSE>>=

post <- sample.naive.posterior(list(m2a,m2b),n = 5e4, method="AICc", nobs=nrow(d))
fore.mean <- mean(d$fs)

y.pred <- sapply(pct.seq , function(z) mean(exp(post$a + post$b.P*z + post$b.F*fore.mean)))

y.pred.ci <- sapply( pct.seq , function(z) PCI(exp(post$a + post$b.P*z + post$b.F*fore.mean)))

y.pred.pi <- sapply( pct.seq , function(z) PCI( rpois( n=3e4, lambda=exp(post$a + post$b.P*z + post$b.F*fore.mean)))) 

@ 


<<cor-issue,message=FALSE,cache=TRUE>>=
d$cover <- factor(ifelse(d$pc >0, "> 60", " < 60"))
g1 <- ggplot(d)
g1 <- g1+geom_boxplot(aes(cover, SALAMAN))+geom_point(aes(cover, SALAMAN,size=FORESTAGE))

rate.param <- function(x){ mean(exp(coef(m2a)['a'] + coef(m2a)['b.P']*x))}

d <- d[order(d$pc),]
d$cover <- c(rep(0,10), rep(1, 10), rep(2,10), rep(3,10), rep(4,7))
d$cover <- as.factor(d$cover)

d.q <- data.frame(lambda=tapply(d$SALAMAN, d$cover, rate.param, simplify=TRUE))
d.q$mean <- tapply(d$SALAMAN, d$cover, mean, simplify=TRUE)
d.q$variance <-  tapply(d$SALAMAN, d$cover, var, simplify=TRUE)

g2 <- ggplot(d.q)
g2 <- g2 + geom_abline(intercept=0, slope=1, color='gray')+ geom_point(aes(mean, variance, size=lambda)) + xlim(c(0,20))+ opts(title="salamander count overdispersion")
require(gridExtra)
grid.arrange(g1,g2, ncol=1)
@ 

Visualized another way (top plot), one can see massive spread in count at high percent cover (> 60\%) and very little pattern in forestage (dot size) at these values of percent cover.
In this light, it's unsurprising that forestage didn't help much. 

But there may also be deeper reasons why the model didn't work, even for our single predictor of percent cover.
In the Poisson distribution the mean should be equal to the variance. 
A variance exceeding the mean is called (at least in the parasite literature) over-dispersion.

Salamanders do, in fact, show overdispersion (bottom plot). 
This figure plots the (sample) variance against mean for SALAMAN binned across increasing values of PCTCOVER (bin width 10).
Within each bin, SALAMAN displays overdispersion (variance exceeding the mean), while a Poisson distribution always has variance equal to mean (with predicted value lambda shown by dot size). 
This means that any model for salamander count as a Poisson outcome with a relatively fixed mean for bins of PCTCOVER will be unable to explain the variance in salamander counts. 

So how would one improve this?
As I pointed out above, if age of the tree cover (FORESTAGE) were a good predictor,  a regression based on both predictors {\em could} do a better job. 
Tree cover age, however, was a very poor predictor.
Absent a good predictor, an alternative would be to specifiy a distribution that displays overdispersion, e.g. negative-binomial or some zero-inflated mixture. 


\subsection*{Colophon}

<<runit,eval=FALSE>>=
require(knitr) ### the package
knit(paste(getwd(),'hw7ashander.Rnw',sep='/')) ## to run

## to use all cores
require(snowfall)
sfInit(parallel=TRUE,cpus=4)
sfLibrary(rethinking)
sfExportAll()
sfStop()
@ 

\end{document}
