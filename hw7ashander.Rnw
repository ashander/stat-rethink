\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
%\usepackage{breakurl}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\makeatother

\begin{document}

%% still can't get paths to work ...
\SweaveOpts{path=fig/hw7-,fig.align=center,fig.show=hold,dev=png,fig.width=6,fig.height=4}

<<setup,echo=FALSE,results=hide,message=FALSE>>=
options(replace.assign=TRUE,width=90)
knit_hooks$set(par=function(before, options, envir){if (before) par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3,las=1)})
require(bbmle)
require(rethinking)
require(ggplot2)
@

\begin{center}
  {\bf \Large Homework 7, Statistical Rethinking}\\
\vspace{12pt}
   {\large Jaime Ashander}
\end{center}

\subsection*{Pirating eagles}

<<load,message=FALSE>>=
data(eagles)
d <- eagles
names(d)
d
@ 

\begin{itemize}
  \item y: Number of successful attempts.
  \item n: Total number of attempts.
  \item P: Size of pirating eagle ('L' = large, 'S' = small).
  \item A: Age of pirating eagle ('I' = immature, 'A' = adult).
  \item V: Size of victim eagle ('L' = large, 'S' = small).
\end{itemize}

We seek to predict successful pirating attempts based on the size and age of the pirate and the size of the victim.

\subsubsection*{(A)}

To do this, we fit the binomial model:
\begin{align*}
&y_i \sim {\rm Binomial} ( p_i , n_i)\\
&\log \frac{p_i}{1-p_i} = \alpha + \beta_P P_i + \beta_V V_i + \beta_A A_i
\end{align*}

To fit the model, we code dummy variables $P$: {\tt pirateL}, $V$: {\tt victimL}, $A$: {\tt pirateA}.
<<var-code,message=FALSE>>=
d$pirateL <- ifelse(d$P=='L',1,0)
d$pirateA <- ifelse(d$A=='A',1,0)
d$victimL <- ifelse(d$V=='L',1,0)
@ 

To fit the model, we use the logit link function.
In practice, this means using the logistic (inverse link) tranform on the linear model for the log odds (the RHS of the second equation above):

<<pirate-model,message=FALSE>>=
m1a <- mle2(y ~ dbinom(prob=logistic(a + bP*pirateL+bV*victimL + bA*pirateA), size=n), data=d, start=list(a=mean(d$y), bP=0, bV=0, bA=0))
p.m1 <- precis(m1a)
point.est <- as.data.frame(t(p.m1$Estimate))
names(point.est) <- row.names(p.m1)
p.m1
@ 

The baseline probability of success (i.e. given default vales for dummy variables) corresponds to a small, young pirate versus a small victim.
In this case, the probability of success in an attack is a bit over half (0.65 = logistic($\alpha$)).
A larger or older eagle has a greater chance of success, but being larger is more helpful than being older. 
An attack on a larger victim is less likely to succeed. 
The effect of largeness in either the victim or pirate on log-odds of success is about equal (but opposite). 

<<probs,echo=FALSE>>=
cat('small, young v small',  logistic(with(point.est, a)),'\n')
cat('small, old v small', logistic(with(point.est, bA+a)), '\n')
cat('large, young v large', logistic(with(point.est, a+bP+bV)), '\n')
cat('large, young v small', logistic(with(point.est, a+bP)), '\n')
cat('large, old v small', logistic(with(point.est, a+bP+bA)), '\n')
cat('large, old v large',logistic(with(point.est, a+bP+bA+bV)), '\n')
cat('small, old v large',logistic(with(point.est, a+bA+bV)),'\n')
cat('small, young v large', logistic(with(point.est, a+bV)), '\n')
@ 

\subsubsection*{(B)}

<<pirate-plot-b1,message=TRUE,cache=TRUE>>=
post <- sample.naive.posterior( m1a)

y.pred <- sapply( 1:nrow(d) , function(i) mean( rbinom( n=10000 , prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] ) , size=d$n[i] ) ) )

y.pred.ci <- sapply( 1:nrow(d) , function(i) PCI( rbinom( n=10000 , prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] ) , size=d$n[i] ) ) )

#op <- par(mfrow=c(2,1))
plot( (1:8)+0.2 , d$y , col="slateblue" , ylab="successful attempts" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,31), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]),col='grey')
points( 1:8 , y.pred ,pch=19,cex=0.5,col='black')

plot( (1:8)+0.2 , d$y/d$n , col="slateblue" , ylab="proportion successful" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,1), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]/d$n[i]),col='grey')
points( 1:8 , y.pred/d$n ,pch=19,cex=0.5,col='black')

#par(op)
@ 

Counts of success plot (first figure):

shows heterogeneity in relative frequency of successful attempts across encounter types

confidence intervals and point estimates easier to interpret relative to the data

Proportional plot (second figure): 

shows heterogeneity in probability across encounter types

confidence intervals provide better depiction of uncertainty in outcome



\subsubsection*{(C)}

We'd like to improve the model, so we  fit the interaction model 
\begin{align*}
&y_i \sim {\rm Binomial} ( p_i , n_i)\\
&\log \frac{p_i}{1-p_i} = \alpha + \beta_P P_i + \beta_V V_i + \beta_A A_i + \beta_{PA} P_i \cdot A_i
\end{align*}

<<better-model,message=FALSE,cache=TRUE>>=
m1c <- mle2(y ~ dbinom(prob=logistic(a + bP*pirateL + bV*victimL + bA*pirateA + bPA*pirateL*pirateA), size=n), data=d, start=list(a=mean(d$y), bP=0, bV=0, bA=0, bPA=0))
p.m1c <- precis(m1c)

compare(m1a,m1c, nobs=sum(d$n))
@ 


<<better-model-fig,message=FALSE,cache=TRUE>>=
rm(list=c('post','y.pred','y.pred.ci'))
post <- sample.naive.posterior( list(m1a,m1c),method='AICc', nobs=sum(d$n),n=3e4)

y.pred <- sapply( 1:nrow(d) , function(i) mean( rbinom( n=10000, prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] + post$bPA*d$pirateL[i]*d$pirateA[i] ) , size=d$n[i] ) ) )

y.pred.ci <- sapply( 1:nrow(d) , function(i) PCI( rbinom( n=10000, prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] + post$bPA*d$pirateL[i]*d$pirateA[i] ) , size=d$n[i] ) ) )

#op <- par(mfrow=c(2,1))
plot( (1:8)+0.2 , d$y , col="slateblue" , ylab="successful attempts" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,31), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]),col='grey')
points( 1:8 , y.pred ,pch=19,cex=0.5,col='black')

plot( (1:8)+0.2 , d$y/d$n , col="slateblue" , ylab="proportion successful" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,1), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]/d$n[i]),col='grey')
points( 1:8 , y.pred/d$n ,pch=19,cex=0.5,col='black')

#par(op)

@ 

\subsection*{Herptiles}

<<load-herp,message=FALSE>>=
data(salamanders)
d <- salamanders
head(d,n=1)
@ 

The data set includes counts of salamanders in each plot (SALAMAN), as well as percent (PCTCOVER) and age (FORESTAGE) of ground cover.



\subsubsection*{(A)}

I model the count variable SALAMAN as a Poisson variable:
\begin{align*}
&S_i \sim {\rm Poisson} ( \lambda_i)\\
&\log \lambda = \alpha + \beta_P *P_i
\end{align*}
where $S_i$ is SALAMAN and $P_i$ is PCTCOVER

<<sal-model,message=FALSE>>=
m2a <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*PCTCOVER)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0))
precis(m2a)
@ 


<<sal-fig,message=FALSE,cache=TRUE>>=
post <- sample.naive.posterior(m2a)
pct.seq <- 0:100

y.pred <- sapply(pct.seq , function(z) mean(exp(post$a + post$b.P*z)))
n
y.pred.ci <- sapply( pct.seq , function(z) PCI(exp(post$a + post$b.P*z)))

y.pred.pi <- sapply( pct.seq , function(z) PCI( rpois( n=3e4, lambda=exp(post$a + post$b.P*z)))) 


plot(SALAMAN~PCTCOVER, data=d,col=col.alpha('gray', .9), pch=19)
lines(pct.seq, y.pred)
lines(pct.seq, y.pred.ci[1,], lty=2)
lines(pct.seq, y.pred.ci[2,], lty=2)
lines(pct.seq, y.pred.pi[1,], lty=3)
lines(pct.seq, y.pred.pi[2,], lty=3)
@ 

The model does a good job at low percent ground cover, with all observation falling within the 95\% PI. 
At very high coverages, however, there are some high counts that are not captured by the model.


\subsubsection*{(B)}

<<sal-model,message=FALSE>>=
m2b <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*PCTCOVER + b.F*FORESTAGE)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0, b.F=0))
m2c <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*PCTCOVER + b.F*FORESTAGE + b.PF*PCTCOVER*FORESTAGE)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0, b.F=0, b.PF=0))
m2d <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.F*FORESTAGE)), data=d, start=list(a=log(mean(d$SALAMAN)), b.F=0))
compare(m2a,m2b,m2c,m2d, nobs=nrow(d))

@ 


<<notmuchinfo,message=FALSE,cache=TRUE>>=
pairs(d[,2:4])
@ 

\subsection*{Colophon}

<<runit,eval=FALSE>>=
require(knitr) ### the package
knit(paste(getwd(),'hw7ashander.Rnw',sep='/')) ## to run

## to use all cores
require(snowfall)
sfInit(parallel=TRUE,cpus=4)
sfLibrary(rethinking)
sfExportAll()
sfStop()
@ 

\end{document}
