\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
%\usepackage{breakurl}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\makeatother

\begin{document}

%% still can't get paths to work ...
%\SweaveOpts{path=fig/hw7-,fig.align=center,fig.show=hold,dev=png,fig.width=6,fig.height=4}

<<setup,echo=FALSE,results=hide,message=FALSE>>=
options(replace.assign=TRUE,width=90)
knit_hooks$set(par=function(before, options, envir){if (before) par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3,las=1)})
require(bbmle)
require(rethinking)
require(ggplot2)
@

\begin{center}
  {\bf \Large Homework 7, Statistical Rethinking}\\
\vspace{12pt}
   {\large Jaime Ashander}
\end{center}

\subsection*{Pirating eagles}

<<load,message=FALSE>>=
data(eagles)
d <- eagles
names(d)

@ 

\begin{itemize}
  \item y: Number of successful attempts.
  \item n: Total number of attempts.
  \item P: Size of pirating eagle ('L' = large, 'S' = small).
  \item A: Age of pirating eagle ('I' = immature, 'A' = adult).
  \item V: Size of victim eagle ('L' = large, 'S' = small).
\end{itemize}

We seek to predict successful pirating attempts based on the size and age of the pirate and the size of the victim.

\subsubsection*{(A)}

To do this, we fit the binomial model:
\begin{align*}
&y_i \sim {\rm Binomial} ( p_i , n_i)\\
&\log \frac{p_i}{1-p_i} = \alpha + \beta_P P_i + \beta_V V_i + \beta_A A_i
\end{align*}

To fit the model, we code dummy variables $P$: {\tt pirateL}, $V$: {\tt victimL}, $A$: {\tt pirateA}.
<<var-code,message=FALSE>>=
d$pirateL <- ifelse(d$P=='L',1,0)
d$pirateA <- ifelse(d$A=='A',1,0)
d$victimL <- ifelse(d$V=='L',1,0)
@ 

To fit the model, we use the logit link function.
In practice, this means using the logistic (inverse link) tranform on the linear model for the log odds (the RHS of the second equation above):

<<pirate-model,message=FALSE>>=
m1a <- mle2(y ~ dbinom(prob=logistic(a + bP*pirateL+bV*victimL + bA*pirateA), size=n), data=d, start=list(a=mean(d$y), bP=0, bV=0, bA=0))
p.m1 <- precis(m1a)
point.est <- as.data.frame(t(p.m1$Estimate))
names(point.est) <- row.names(p.m1)
p.m1
@ 

The baseline probability of success (i.e. given default vales for dummy variables) corresponds to a small, young pirate versus a small victim.
In this case, the probability of success in an attack is a bit over half (0.65 = logistic($\alpha$)).
A larger or older eagle has a greater chance of success, but being larger is more helpful than being older. 
An attack on a larger victim is less likely to succeed. 
The effect of largeness in either the victim or pirate on log-odds of success is about equal (but opposite). 

<<probs,echo=FALSE>>=
cat('small, young v small',  logistic(with(point.est, a)),'\n')
#cat('small, old v small', logistic(with(point.est, bA+a)), '\n')
cat('large, young v small', logistic(with(point.est, a+bP)), '\n')
cat('large, young v large', logistic(with(point.est, a+bP+bV)), '\n')
cat('large, old v small', logistic(with(point.est, a+bP+bA)), '\n')
#cat('large, old v large',logistic(with(point.est, a+bP+bA+bV)), '\n')
#cat('small, old v large',logistic(with(point.est, a+bA+bV)),'\n')
#cat('small, young v large', logistic(with(point.est, a+bV)), '\n')
@ 

\subsubsection*{(B)}

<<pirate-plot-b1,message=TRUE,cache=TRUE>>=
post <- sample.naive.posterior( m1a)

y.pred <- sapply( 1:nrow(d) , function(i) mean( rbinom( n=10000 , prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] ) , size=d$n[i] ) ) )

y.pred.ci <- sapply( 1:nrow(d) , function(i) PCI( rbinom( n=10000 , prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] ) , size=d$n[i] ) ) )

op <- par(mfrow=c(2,1))
plot( (1:8)+0.2 , d$y , col="slateblue" , ylab="successful attempts" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,31), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]),col='grey')
points( 1:8 , y.pred ,pch=19,cex=0.5,col='black')

plot( (1:8)+0.2 , d$y/d$n , col="slateblue" , ylab="proportion successful" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,1), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]/d$n[i]),col='grey')
points( 1:8 , y.pred/d$n ,pch=19,cex=0.5,col='black')

par(op)

@ 

Counts of success plot (first figure):

shows heterogeneity in relative frequency of successful attempts across encounter types

confidence intervals and point estimates easier to interpret relative to the data

Proportional plot (second figure): 

shows heterogeneity in probability across encounter types

confidence intervals provide better depiction of uncertainty in outcome



\subsubsection*{(C)}

We'd like to improve the model, so we  fit a model with an interaction between pirate age and pirate size
\begin{align*}
&y_i \sim {\rm Binomial} ( p_i , n_i)\\
&\log \frac{p_i}{1-p_i} = \alpha + \beta_P P_i + \beta_V V_i + \beta_A A_i + \beta_{PA} P_i \cdot A_i
\end{align*}

<<better-model,message=FALSE,cache=TRUE>>=
m1c <- mle2(y ~ dbinom(prob=logistic(a + bP*pirateL + bV*victimL + bA*pirateA + bPA*pirateL*pirateA), size=n), data=d, start=list(a=mean(d$y), bP=0, bV=0, bA=0, bPA=0))
p.m1c <- precis(m1c)

compare(m1a,m1c, nobs=sum(d$n))
@ 


<<better-model-fig,message=FALSE,cache=TRUE>>=
rm(list=c('post','y.pred','y.pred.ci'))
post <- sample.naive.posterior( list(m1a,m1c),method='AICc', nobs=sum(d$n),n=3e4)

y.pred <- sapply( 1:nrow(d) , function(i) mean( rbinom( n=10000, prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] + post$bPA*d$pirateL[i]*d$pirateA[i] ) , size=d$n[i] ) ) )

y.pred.ci <- sapply( 1:nrow(d) , function(i) PCI( rbinom( n=10000, prob=logistic( post$a + post$bP*d$pirateL[i] + post$bV*d$victimL[i] + post$bA*d$pirateA[i] + post$bPA*d$pirateL[i]*d$pirateA[i] ) , size=d$n[i] ) ) )

op <- par(mfrow=c(2,1))
plot( (1:8)+0.2 , d$y , col="slateblue" , ylab="successful attempts" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,31), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]),col='grey')
points( 1:8 , y.pred ,pch=19,cex=0.5,col='black')

plot( (1:8)+0.2 , d$y/d$n , col="slateblue" , ylab="proportion successful" , xlab="case" , xaxt="n" , xlim=c(0.75,8.25) , pch=16 ,ylim=c(0,1), cex=0.5)
axis( 1 , at=1:8 , labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ) )
for(i in 1:8) lines(c(i,i), c(y.pred.ci[,i]/d$n[i]),col='grey')
points( 1:8 , y.pred/d$n ,pch=19,cex=0.5,col='black')

par(op)

@ 

\subsection*{Herptiles}

<<load-herp,message=FALSE>>=
data(salamanders)
d <- salamanders
head(d,n=1)
d$pc <- d$PCTCOVER - mean(d$PCTCOVER)
d$fs <- d$FORESTAGE - mean(d$FORESTAGE)

@ 

The data set includes counts of salamanders in each plot (SALAMAN), as well as percent (PCTCOVER) and age (FORESTAGE) of ground cover.
I recenter the predictors. 


\subsubsection*{(A)}

I model the count variable SALAMAN as a Poisson variable:
\begin{align*}
&S_i \sim {\rm Poisson} ( \lambda_i)\\
&\log \lambda_i = \alpha + \beta_P *P_i
\end{align*}
where $S_i$ is SALAMAN and $P_i$ is PCTCOVER

<<sal-model,message=FALSE>>=
m2a <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*pc)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0))
precis(m2a)
@ 


<<sal-fig,message=FALSE,cache=TRUE>>=
post <- sample.naive.posterior(m2a)
pct.seq <- seq(min(d$pc),max(d$pc), length.out=100)

y.pred <- sapply(pct.seq , function(z) mean(exp(post$a + post$b.P*z)))
n
y.pred.ci <- sapply( pct.seq , function(z) PCI(exp(post$a + post$b.P*z)))

y.pred.pi <- sapply( pct.seq , function(z) PCI( rpois( n=3e4, lambda=exp(post$a + post$b.P*z)))) 

plot(SALAMAN~pc, data=d,col=col.alpha('gray', .9), pch=19, xlab='percent cover', xaxt='n')
axis(1, at=pct.seq[c(1, 20, 40, 60, 80)], labels=c(0,2,4,6,8)*10)
lines(pct.seq, y.pred)
lines(pct.seq, y.pred.ci[1,], lty=2)
lines(pct.seq, y.pred.ci[2,], lty=2)
lines(pct.seq, y.pred.pi[1,], lty=3)
lines(pct.seq, y.pred.pi[2,], lty=3)

pairs(d[,c(2:4)])
@ 

The model does a good job at low percent ground cover, with all observation falling within the 95\% PI. 
At very high coverages, however, there are some high counts that are not captured by the model.

Looking at the pairs plot, we can see perhaps why a model based on pc alone does a bad job at high counts. 
At high pc, there are counts ranging from 0 to 12 (the maximum), thus there is little information in pc to predict  at these counts. 
There are a wide range of forestage values at high percent-cover values, however, and if forestage were a strong predictor of salamander count, a model with both variables could work well. 

There's a big problem, however, with forestage as a predictor. This can be seen in the pairs plot.

\subsubsection*{(B)}

We'll see if model selection and averaging bears out our suspicion that forestage can't help much. . . 

<<sal-model,message=FALSE>>=
m2b <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*pc + b.F*fs)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0, b.F=0))
m2c <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.P*pc + b.F*fs + b.PF*pc*fs)), data=d, start=list(a=log(mean(d$SALAMAN)), b.P=0, b.F=0, b.PF=0))
m2d <- mle2(SALAMAN ~ dpois(lambda=exp(a + b.F*fs)), data=d, start=list(a=log(mean(d$SALAMAN)), b.F=0))
compare(m2a,m2b,m2c,m2d, nobs=nrow(d))

@ 

There is support for a model that includes both pc and fs, but with more weight on pc alone. 
(BIC and AICc agree pretty well here, so it shouldn't matter which I use)
Averaged predictions (not shown) display no difference from the predictions using pc alone. 
This, in part, because forestage is such a poor predictor. 

<<2b-avg, message=FALSE,cache=TRUE,eval=FALSE>>=

post <- sample.naive.posterior(list(m2a,m2b),n = 5e4, method="AICc", nobs=nrow(d))
fore.mean <- mean(d$fs)

y.pred <- sapply(pct.seq , function(z) mean(exp(post$a + post$b.P*z + post$b.F*fore.mean)))

y.pred.ci <- sapply( pct.seq , function(z) PCI(exp(post$a + post$b.P*z + post$b.F*fore.mean)))

y.pred.pi <- sapply( pct.seq , function(z) PCI( rpois( n=3e4, lambda=exp(post$a + post$b.P*z + post$b.F*fore.mean)))) 

## plot(SALAMAN~pc, data=d,col=col.alpha('gray', .9), pch=19)
## lines(pct.seq, y.pred)
## lines(pct.seq, y.pred.ci[1,], lty=2)
## lines(pct.seq, y.pred.ci[2,], lty=2)
## lines(pct.seq, y.pred.pi[1,], lty=3)
## lines(pct.seq, y.pred.pi[2,], lty=3)
@ 


<<cor-issue,message=FALSE,cache=TRUE>>=
d$cover <- factor(ifelse(d$pc >0, "> 60", " < 60"))
g1 <- ggplot(d)
g1 <- g1+geom_boxplot(aes(cover, SALAMAN))+geom_point(aes(cover, SALAMAN,size=FORESTAGE))

rate.param <- function(x){ mean(exp(coef(m2a)['a'] + coef(m2a)['b.P']*x))}

d <- d[order(d$pc),]
d$cover <- c(rep(0,10), rep(1, 10), rep(2,10), rep(3,10), rep(4,7))
d$cover <- as.factor(d$cover)

d.q <- data.frame(lambda=tapply(d$SALAMAN, d$cover, rate.param, simplify=TRUE))
d.q$mean <- tapply(d$SALAMAN, d$cover, mean, simplify=TRUE)
d.q$variance <-  tapply(d$SALAMAN, d$cover, var, simplify=TRUE)

g2 <- ggplot(d.q)
g2 <- g2 + geom_abline(intercept=0, slope=1, color='gray')+ geom_point(aes(mean, variance, size=lambda)) + xlim(c(0,20))+ opts(title="salamander count overdispersion")
require(gridExtra)
grid.arrange(g1,g2, ncol=1)
@ 

Visualized another way, we see massive spread in count at high percent cover (> 60\%) and very little pattern in forestage (dot size) at these values of percent cover.


So why was the Poisson model bad in teh first place? 
Over-dispersion. 
In the Poisson distribution the mean should be equal to the variance. 


\subsection*{Colophon}

<<runit,eval=FALSE>>=
require(knitr) ### the package
knit(paste(getwd(),'hw7ashander.Rnw',sep='/')) ## to run

## to use all cores
require(snowfall)
sfInit(parallel=TRUE,cpus=4)
sfLibrary(rethinking)
sfExportAll()
sfStop()
@ 

\end{document}
